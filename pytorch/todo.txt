TODO
-Save csv of results for both training and testing
-Periodically evaluate on test data during training?
-Try moving the loss calculation to the GPU to see if it affects run time

LOG
-Save profile parameters in model folder
-Residual learning
-Plug and play loss functions
-Consolidated control over batch size, patch size, number of augmentations, etc.
-Refactor Dataset code. Allow for selection of a forward model, which takes in numpy arrays and outputs numpy arrays, and can be used for both training and testing.
-Run isoplanatic.py code on anaconda and make sure that results are as expected
-Update test.py
-Create new repository (https://stackoverflow.com/questions/38831301/how-to-un-fork-the-github-repository)